The bank processes thousands of transactions daily, yet currently lacks an automated solution to label transaction purposes efficiently. Without such a system, lines of business (LOBs) must assemble teams of analysts who spend close to a month manually tagging transactions with purposes. Even after this labor-intensive effort, there is no centralized repository for publishing or sharing their findings. This absence of a unified platform leads to duplicated efforts among teams addressing similar requests. Consequently, reports are often inconsistent due to multiple sources of truth, exacerbating inefficiencies and hindering operational alignment.

Furthermore, this manual process introduces a significant lag in reporting. Senior management, seeking immediate insights into sudden drops in deposits or unusual transaction patterns, cannot afford the delays caused by manual tagging. They require near real-time understanding of where funds are moving and the underlying reasons for these shifts to make timely decisions.

Our newly developed hybrid model addresses these challenges by combining business rules with machine learning to score transactions at scale and in near real-time. This dual-layer approach provides enhanced granularity and flexibility, as transactions can simultaneously have multiple purposes. For instance, a transaction originating from a Tesla account might pertain to an inventory invoice, and therefore its purposes could be classified as “Tesla,” “invoice,” and “inventory purchases.” By scoring transactions with both business rules and machine learning, the model offers richer insights, enabling LOBs and senior management to make faster, more informed decisions while eliminating inefficiencies and ensuring consistency across teams.

The transaction purpose identification model employs a combination of business rules, keyword searches, and machine learning to enrich transactions with one or multiple purposes.

Business Rules: These rules are primarily account number-driven and are already familiar to the business. They serve as a foundational layer for tagging transactions based on predefined criteria.

Keyword Search: This method includes 50 broader categories, such as "Inventory Purchase," "Invoice," and "Bank-to-Bank Transfer," which were derived through collaboration with LOB. The keyword search examines the transaction description field along with other fields to assign relevant purposes.

Machine Learning: Using natural language processing (NLP) techniques, the machine learning component analyzes transaction description fields and other variables, such as sender/receiver names, to classify transaction purposes. The model outputs the category with the highest probability.

To ensure comprehensive insights, the model applies all three methods—business rules, keyword searches, and machine learning—to the data. Results from each method are stored in separate columns, allowing users to access multiple layers of insights and compare findings when differences arise.

Dependent Variable Definition and Labeling

The data used for the transaction purpose identification model was initially unlabeled, requiring the creation of proxies to label the data.

Wire Rules: The first step involved using predefined wire rules to identify transactions that were already familiar to the LOB. Transactions that were not covered by the business rules were then passed to the next phase.

Keyword Search Rules: To expand the labeled dataset, the team developed keyword search rules. These rules looked for specific keywords associated with a category, primarily within the OBI field, as well as in fields such as beneficiary name and originating name.

The team engaged in a highly iterative process with the LOB to refine these rules. Proposed rules were tested and shared with the LOB for review. Based on their feedback, keywords were added, removed, or modified to improve accuracy. Through this collaborative process, the team finalized approximately 50 keyword rules. A chart detailing all keyword search logic will be attached below to provide further clarity.

These 50 categories became the training data labels for the model. The machine learning component of the model uses this labeled data to identify patterns beyond the fields used for labeling, such as OBI, beneficiary name, and originating name. It also incorporates additional fields like debit/credit account numbers and sender/receiver name information to capture the pattern of the purpose code effectively. This approach ensures that the model generalizes effectively and captures broader transaction patterns, providing reliable dependent variables for training.


The input data is formatted as a matrix, which is the result of applying multiple NLP techniques to clean and transform the text column. The text column was formed by concatenating seven raw input columns into a single long string, with each string separated by a white space. This transformation ensures that the data is in a structured format suitable for model training and fitting.

The dependent variable is derived from the results of keyword searches, which classify transactions into one of 50 predefined categories. These categories serve as the class labels for the model. In production, the model will use these labels to classify incoming transactions into their respective transaction purpose categories.



Collaborated with the Line of Business (LOB) to develop a master taxonomy for storing all known business rules, primarily account number-driven, with some special rules utilizing additional attributes. Designed merging logic to label a subset of the data using these business rules.
Partnered with the LOB to create 48 keyword-based rules for labeling transactions by searching within the OBI, org_name, and bnf_name fields. These keyword results also run on the data labeled by business rules to provide an additional layer of insights.
Implemented a multi-class classification model to predict purpose codes for transactions not covered by rules or keyword searches. The model was trained using proxy labels derived from the OBI keyword results to learn patterns and make predictions based on the highest probability.
Published the final results back to the ILMS system for the Treasury team’s consumption. The output includes three columns: business rules results, OBI keyword search results, and ML prediction results.


The transaction purpose identification model employs a hybrid framework comprising wires rules, OBI keyword searches, and an ML component to maximize coverage and accuracy while minimizing the risk of misclassification. This approach ensures a structured and efficient methodology for handling complex transactional data.

Wires Rules
The wires rules are predefined and well-understood by the Line of Business (LOB), making them the most reliable component of the framework. These rules are primarily account number-driven and introduce minimal uncertainty. To ensure accuracy and prevent misclassification, a rule-based approach was adopted to label this portion of the data.

OBI Keyword Searches
The OBI keyword searches are the result of an iterative collaboration with the LOB, leveraging their domain expertise to define keywords that align with common transaction categories. This component not only provides an additional layer of insights on top of the wires rules but also acts as the training data for the ML model. Since the data is inherently unlabeled, OBI keyword searches serve as a proxy labeling mechanism.

The current set of keywords represents the best possible iteration based on available information. As the model operates in production, user feedback will be collected to refine and improve the OBI keyword rules over time.
The long-term objective is to increase OBI keyword coverage while reducing reliance on the ML model, thereby minimizing uncertainty and improving interpretability.
ML Component
The ML model is designed to handle the most challenging portion of the data, which is characterized by a high proportion of null or unstructured values.

Some null values stem from a known data issue, which will be addressed by the ILMS 2.0 system scheduled for production in Q3 2025. Others result from unstandardized input formats by customers, making fields such as the OBI field occasionally uninformative.
To mitigate these challenges, the ML model incorporates a broader set of features, including account numbers, sender and receiver information, and the transaction description fields (OBI, bnf_name, and org_name). This holistic feature set ensures the model can identify patterns indicative of transaction purpose codes.
Additionally, the LOB manually reviewed the ML model’s predictions and restricted its use to top-performing categories, significantly reducing the risk of misclassification within this complex dataset.
This hybrid approach ensures that each component contributes to the overall robustness of the framework, effectively balancing the strengths of rule-based methods and machine learning to achieve a comprehensive and reliable solution.



import random
from pyspark.sql.functions import udf, lit
from pyspark.sql.types import StringType

# QWERTY keyboard adjacency mapping for realistic typos
keyboard_adjacent = {
    'q': 'wa', 'w': 'qse', 'e': 'wsdr', 'r': 'etdf', 't': 'ryfg', 'y': 'tugh', 'u': 'yihj',
    'i': 'uojk', 'o': 'ipkl', 'p': 'ol',
    'a': 'qwsz', 's': 'awedxz', 'd': 'serfcx', 'f': 'drtgvc', 'g': 'ftyhbv', 'h': 'gyujnb',
    'j': 'huikm', 'k': 'jiolm', 'l': 'kop',
    'z': 'asx', 'x': 'zsdc', 'c': 'xdfv', 'v': 'cfgb', 'b': 'vghn', 'n': 'bhjm', 'm': 'njk',
}

def introduce_typos(text, typo_ratio):
    """Introduce typos based on a given typo ratio."""
    if not text or typo_ratio <= 0:
        return text  # Return unchanged if empty or no typo needed

    text = list(text)  # Convert to list for mutability
    num_typos = int(len(text) * typo_ratio)  # Compute number of typos

    for _ in range(num_typos):
        idx = random.randint(0, len(text) - 1)  # Pick a random character index
        char = text[idx]

        typo_type = random.choice(["swap", "replace", "delete", "insert"])

        if typo_type == "swap" and idx < len(text) - 1:
            text[idx], text[idx + 1] = text[idx + 1], text[idx]

        elif typo_type == "replace" and char.lower() in keyboard_adjacent:
            text[idx] = random.choice(keyboard_adjacent[char.lower()])

        elif typo_type == "delete" and len(text) > 1:
            text.pop(idx)

        elif typo_type == "insert" and char.lower() in keyboard_adjacent:
            text.insert(idx, random.choice(keyboard_adjacent[char.lower()]))

    return "".join(text)

# Convert the function into a PySpark UDF
typo_udf = udf(lambda text, ratio: introduce_typos(text, float(ratio)), StringType())

# Apply different typo ratios
df_test = df_test.withColumn("typo_10", typo_udf(df_test["stemmed_words"], lit(0.1)))
df_test = df_test.withColumn("typo_20", typo_udf(df_test["stemmed_words"], lit(0.2)))
df_test = df_test.withColumn("typo_30", typo_udf(df_test["stemmed_words"], lit(0.3)))

# Show results
df_test.select("stemmed_words", "typo_10", "typo_20", "typo_30").show(truncate=False)

